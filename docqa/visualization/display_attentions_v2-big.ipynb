{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "workdir = \"/Users/mihaylov/research/qa-knowreader-long-docs\"\n",
    "sys.path.append(\"/Users/mihaylov/research/qa-knowreader-long-docs\")\n",
    "sys.path.append(\"/Users/mihaylov/research/qa-knowreader-long-docs/docqa\")\n",
    "\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated cache directory found (/Users/mihaylov/.allennlp/datasets).  Please remove this directory from your system to free up space.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/allennlp/commands/find_learning_rate.py:55: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2852, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 314, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/Users/mihaylov/anaconda3/envs/docqa/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "from docqa.commands.evaluate_qanet_semantic_flat import *\n",
    "from docqa.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#debug\n",
    "model_path = \"_trained_models/qanet_semantic_flat_concat_sdp_debug/model.tar.gz\"\n",
    "\n",
    "# model_path = \"_trained_models/bidaf_qa_sumary_span_custom_multiview_eval/model.tar.gz\"\n",
    "# item_ids = \"00936497f5884881f1df23f4834f6739552cee8b##016[15:30];00936497f5884881f1df23f4834f6739552cee8b##005[17:45];0029bdbe75423337b551e42bb31f9a102785376f##023\"\n",
    "# evaluation_data_file = \"/Users/mihaylov/research/document-parsing-pipeline/tests/fixtures/data/narrativeqa/third_party/wikipedia/summaries-all.csv.parsed.jsonl.srl.jsonl.with_q_spans.jsonl.with_exp.with_sdp.json.train.2\"\n",
    "# output_file = \"predictions_dev_jup.json\"\n",
    "\n",
    "model_path=\"_trained_models/summary_context_and_question_span_qanet_semantic_flat_concat_hs128_drop0.1_ml_srl_3verbs.json_19-04-30-17-52-03/model.tar.gz\"\n",
    "item_ids = \"f4c9b2e062c118b0c15409e78b8e2a3c2ceadcd3##013[179:216];0d0bc01441afbec48663e3b38827e1529a287765##018[145:229]\"\n",
    "item_ids = \"0d0bc01441afbec48663e3b38827e1529a287765##018[145:229]\"\n",
    "evaluation_data_file = \"/Users/mihaylov/research/document-parsing-pipeline/tests/fixtures/data/narrativeqa/third_party/wikipedia/summaries-all.csv.parsed.jsonl.srl.jsonl.with_q_spans.jsonl.with_exp.with_sdp.json.test\"\n",
    "output_file = \"predictions_test_vis.json\"\n",
    "\n",
    "args_ns = create_argparse_namespace(archive_file = workdir + \"/\"+model_path,\n",
    "                              evaluation_data_file = evaluation_data_file,\n",
    "                              output_file = \"predictions_dev_jup.json\",\n",
    "                              item_ids = item_ids,\n",
    "                              cuda_device = -1,\n",
    "                              batch_size = 1,\n",
    "                              output_attention = \"True\",\n",
    "                              file_open_mode = \"w\",\n",
    "                              overrides = \"\",\n",
    "                              display_attention_matplot = \"True\",\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(data, x, y, ax, x2=None, y1=None):\n",
    "    seaborn.heatmap(data, \n",
    "                    xticklabels=x,\n",
    "                    yticklabels=y, \n",
    "                    vmin=0.0, vmax=1.0, \n",
    "                    square=True, \n",
    "                    cbar=False, ax=ax)\n",
    "\n",
    "    \n",
    "def format_token(tkn_id, tkn, best_span, gold_span):\n",
    "    prefix = \"\"\n",
    "    suffix = \"\"\n",
    "    if tkn_id == best_span[0]:\n",
    "        prefix += \"[\" \n",
    "    if tkn_id == gold_span[0]:\n",
    "        prefix += \"{\" \n",
    "    if tkn_id == gold_span[1]:\n",
    "        suffix += \"}\" \n",
    "    if tkn_id == best_span[1]:\n",
    "        suffix += \"]\" \n",
    "        \n",
    "    return prefix + tkn + suffix\n",
    "        \n",
    "    \n",
    "def display_attentions(tokens, meta, output, output_metadata, feat_id_to_feat_name, crop_range):\n",
    "    modeling_layer_output = output_metadata[\"modeling_layer\"]\n",
    "    modeling_layer_iters = sorted(list(modeling_layer_output.keys()))\n",
    "    \n",
    "    #selected_span = output[\"best_span\"].data[0].tolist()\n",
    "    #gold_span = meta[\"token_spans\"][0]\n",
    "    #tokens = [format_token(tkn_id, tkn, selected_span, gold_span) for tkn_id, tkn in enumerate(metadata[\"passage_tokens\"])]\n",
    "    if crop_range is not None:\n",
    "        print(crop_range)\n",
    "        tokens = tokens[crop_range[0]: crop_range[1]]\n",
    "        \n",
    "    print(tokens)\n",
    "    \n",
    "    axs_head_iter = None\n",
    "    for iter_key_id, iter_key in enumerate(modeling_layer_iters):\n",
    "        iter_value = modeling_layer_output[iter_key]\n",
    "        print(\"-\" + iter_key)\n",
    "        \n",
    "        if iter_value is None:\n",
    "            continue\n",
    "            \n",
    "        encoder_blocks = sorted(list(iter_value.keys()))\n",
    "        encoder_blocks_cnt = len(encoder_blocks)\n",
    "        for encoder_block_id, encoder_block_key in enumerate(encoder_blocks):\n",
    "            print(\"--\" + encoder_block_key)\n",
    "            \n",
    "            encoder_block_value = iter_value[encoder_block_key]\n",
    "                                  \n",
    "            attention_value = encoder_block_value[\"attention\"]\n",
    "            if isinstance(attention_value, list):\n",
    "                attention_value = np.array(attention_value)\n",
    "            \n",
    "            semantic_views_q_value = encoder_block_value.get(\"semantic_views_q\", None)\n",
    "            if semantic_views_q_value is not None and not isinstance(semantic_views_q_value, list):\n",
    "                semantic_views_q_value = semantic_views_q_value.tolist()\n",
    "            \n",
    "            semantic_views_sent_mask_value = encoder_block_value.get(\"semantic_views_sent_mask\", None)\n",
    "            if semantic_views_sent_mask_value is not None and not isinstance(semantic_views_sent_mask_value, list):\n",
    "                semantic_views_sent_mask_value = semantic_views_sent_mask_value.tolist()\n",
    "        \n",
    "            num_heads = attention_value.shape[0]\n",
    "            if axs_head_iter is None:\n",
    "                fig, axs_head_iter = plt.subplots(num_heads, len(modeling_layer_iters) * encoder_blocks_cnt, \n",
    "                                                  figsize=(90 * encoder_blocks_cnt, 240))\n",
    "                \n",
    "            for head_id in range(num_heads):\n",
    "                head_attention = attention_value[head_id]\n",
    "                semantic_views_q_curr = None\n",
    "                if semantic_views_q_value is not None:\n",
    "                    semantic_views_q_curr = semantic_views_q_value[head_id]\n",
    "                    \n",
    "                if semantic_views_sent_mask_value is not None:\n",
    "                    semantic_views_sent_mask_curr = semantic_views_sent_mask_value[head_id]\n",
    "                \n",
    "                #print(\"mask:\")\n",
    "                #print(semantic_views_sent_mask_curr)\n",
    "                # normalize in [0,1.0]\n",
    "                \n",
    "                if crop_range is not None:\n",
    "                    head_attention = head_attention[crop_range[0]:crop_range[1], crop_range[0]:crop_range[1]]\n",
    "                \n",
    "                    if semantic_views_q_curr is not None :\n",
    "                        semantic_views_q_curr[crop_range[0]:crop_range[1]]\n",
    "                \n",
    "                print(\"head_attention{4}:max={0}, min={1}, mean={2}, std={3}\".format(head_attention.max(), head_attention.min(), head_attention.mean(), head_attention.std(), head_id))\n",
    "                head_attention = head_attention/max(0.001, head_attention.max())\n",
    "                \n",
    "                feats = []\n",
    "                if semantic_views_q_curr is not None:\n",
    "                    feats = [feat_id_to_feat_name.get(int(x), \"\") for x in semantic_views_q_curr]\n",
    "                \n",
    "                axs = axs_head_iter[head_id][iter_key_id * encoder_blocks_cnt + encoder_block_id]\n",
    "                axs.set_title(\"iter {0}, block {1}, head {0}\".format(iter_key_id, encoder_block_id, head_id))\n",
    "                #fig, axs = plt.subplots(1, figsize=(10, 10))\n",
    "                draw(head_attention, tokens, tokens if iter_key_id == 0 else feats, ax=axs)\n",
    "                \n",
    "#                 break\n",
    "#             break\n",
    "#         break      \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persist data - remove the break at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def replace_json_lists_with_shapes(json_item):\n",
    "    new_json = {}\n",
    "    for key, value in json_item.items():\n",
    "        if isinstance(value, list):\n",
    "            new_json[key] = str(np.array(value).shape)\n",
    "        elif isinstance(value, dict):\n",
    "            new_json[key] = replace_json_lists_with_shapes(value)\n",
    "        elif isinstance(value, list):\n",
    "            new_json[key] = str(value.shape)\n",
    "        \n",
    "    return new_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for working with output of the model\n",
    "def _persist_data_matplot(file_handle, \n",
    "                  metadata, \n",
    "                  model_output, \n",
    "                  id2label=None,\n",
    "                  id_to_meta=None,\n",
    "                  feat_id_to_feat_name=None,\n",
    "                  display_attention_matplot=True) -> None:\n",
    "    if metadata:\n",
    "        batch_size = len(metadata)\n",
    "        for index, meta in enumerate(metadata):\n",
    "            res = {}\n",
    "            item_id = meta.get(\"id\", \"n/a\")\n",
    "            res[\"id\"] = item_id\n",
    "            res[\"meta\"] = meta\n",
    "            # We persist model output which matches batch_size in length and is not a Variable\n",
    "            for key, value in model_output.items():\n",
    "                if key == \"output_metadata\":\n",
    "                    crop_range = None\n",
    "                    if id_to_meta is not None:\n",
    "                        id_meta_curr = id_to_meta.get(item_id, None)\n",
    "                        if id_meta_curr is not None:\n",
    "                            crop_range = id_meta_curr[\"attention_range\"]\n",
    "        \n",
    "                    sequence_len = model_output[\"span_start_logits\"].shape[-1]\n",
    "                    attentions_metadata = attentions_to_json(value, index, batch_size, sequence_len , crop_range)\n",
    "                    attentions_shapes = replace_json_lists_with_shapes(attentions_metadata)\n",
    "                    print(json.dumps(attentions_shapes, indent=4))\n",
    "                    \n",
    "                    print(\"Passage:\")\n",
    "                    print(meta[\"passage_tokens\"])\n",
    "                    print(\"Question:\")\n",
    "                    print(meta[\"question_tokens\"])\n",
    "                    print(\"Gold answer:\")\n",
    "                    gold_span = meta[\"token_spans\"][0]\n",
    "                    print(meta[\"passage_tokens\"][gold_span[0]:gold_span[1]+1])\n",
    "                    \n",
    "                    print(\"Selected answer:\")\n",
    "                    print(meta[\"token_spans\"][0])\n",
    "                    \n",
    "                    print(\"feat_id_to_feat_name:\")\n",
    "                    print(feat_id_to_feat_name)\n",
    "                    display_attentions(meta[\"passage_tokens\"], meta, model_output, attentions_metadata, feat_id_to_feat_name, crop_range)\n",
    "                    # res[\"attentions_metadata\"] = attentions_metadata\n",
    "                    #print(attentions_metadata)\n",
    "\n",
    "                curr_value = value\n",
    "                if isinstance(value, torch.autograd.Variable) or isinstance(value, Tensor):\n",
    "                    curr_value = value.data.tolist()\n",
    "\n",
    "                if not isinstance(curr_value, torch.autograd.Variable) \\\n",
    "                        and isinstance(curr_value, list) \\\n",
    "                        and len(curr_value) == batch_size:\n",
    "                    val = curr_value[index]\n",
    "                    res[key] = val\n",
    "\n",
    "            if \"label_probs\" in res and id2label is not None:\n",
    "                labels_by_probs = sorted([[id2label[li], lp] for li, lp in enumerate(res[\"label_probs\"])], key=lambda x:x[1], reverse=True)\n",
    "                res[\"labels_by_prob\"] = labels_by_probs\n",
    "                res[\"label_predicted\"] = labels_by_probs[0][0]\n",
    "\n",
    "            file_handle.write(json.dumps(res))\n",
    "            file_handle.write(\"\\n\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate evaluate_matplot\n",
    "def evaluate_matplot(model: Model,\n",
    "             instances: Iterable[Instance],\n",
    "             data_iterator: DataIterator,\n",
    "             output_file: str = None,\n",
    "             file_mode=\"w\",\n",
    "             id_to_meta: Dict[str, Any] = {},\n",
    "             feat_id_to_feat_name: Dict[int, str]= {},\n",
    "             display_attention_matplot = False,\n",
    "             ) -> Dict[str, Any]:\n",
    "    model.eval()\n",
    "\n",
    "    iterator = data_iterator(instances, num_epochs=1, shuffle=False)\n",
    "    logger.info(\"Iterating over dataset\")\n",
    "    generator_tqdm = Tqdm.tqdm(iterator, total=data_iterator.get_num_batches(instances))\n",
    "    with ExitStack() as stack:\n",
    "        if output_file is None:\n",
    "            file_handle = None\n",
    "        else:\n",
    "            file_handle = stack.enter_context(open(output_file, file_mode))\n",
    "\n",
    "        for batch in generator_tqdm:\n",
    "            model_output = model(**batch)\n",
    "            metrics = model.get_metrics()\n",
    "            if file_handle:\n",
    "                id2label = model.vocab.get_index_to_token_vocabulary(\"labels\")\n",
    "                _persist_data_matplot(file_handle, batch.get(\"metadata\"), model_output,\n",
    "                              id2label=id2label,\n",
    "                              id_to_meta=id_to_meta,\n",
    "                              feat_id_to_feat_name=feat_id_to_feat_name,\n",
    "                              display_attention_matplot=display_attention_matplot)\n",
    "            description = ', '.join([\"%s: %.2f\" % (name, value) for name, value in metrics.items()]) + \" ||\"\n",
    "            generator_tqdm.set_description(description)\n",
    "\n",
    "    return model.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10557it [00:10, 1014.30it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"modeling_layer\": {\n",
      "        \"modeling_layer_iter_000\": {\n",
      "            \"encoder_block_001\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            },\n",
      "            \"encoder_block_003\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            },\n",
      "            \"encoder_block_005\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            }\n",
      "        },\n",
      "        \"modeling_layer_iter_001\": {\n",
      "            \"encoder_block_001\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            },\n",
      "            \"encoder_block_003\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            },\n",
      "            \"encoder_block_005\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            }\n",
      "        },\n",
      "        \"modeling_layer_iter_002\": {\n",
      "            \"encoder_block_001\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            },\n",
      "            \"encoder_block_003\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            },\n",
      "            \"encoder_block_005\": {\n",
      "                \"attention\": \"(8, 310, 310)\",\n",
      "                \"semantic_views_q\": \"(8, 310)\",\n",
      "                \"semantic_views_sent_mask\": \"(8, 310)\",\n",
      "                \"mask\": \"(310,)\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Passage:\n",
      "['Young', 'fearless', 'prospector', 'Roy', 'Glenister', 'and', 'his', 'older', 'partner', ',', 'Dextry', 'are', 'headed', 'back', 'to', 'Nome', 'on', 'the', 'first', 'ship', 'of', 'the', 'season', ',', 'eager', 'to', 'return', 'to', 'protect', 'their', 'gold', 'claim', 'called', 'the', '\"', 'Midas', '\"', ',', 'which', 'promises', 'to', 'yield', 'them', 'great', 'wealth', '.', 'On', 'the', 'trip', ',', 'they', 'defend', 'a', 'young', 'woman', 'who', 'boards', 'the', 'ship', 'from', 'her', 'pursuersâ\\x80\\x94and', 'who', 'is', 'also', 'intent', 'on', 'reaching', 'Nome', 'as', 'soon', 'as', 'possible', '.', 'Glenister', 'immediately', 'begins', 'to', 'fall', 'for', 'the', 'young', 'beauty', ',', 'who', 'turns', 'out', 'to', 'be', 'Helen', 'Chester', ',', 'niece', 'of', 'Judge', 'Arthur', 'Chester', ',', 'recently', 'appointed', 'as', 'the', 'first', 'federal', 'judge', 'for', 'the', 'Alaska', 'Territoryâ\\x80\\x94the', '\"', 'law', '\"', 'is', 'coming', 'to', 'the', 'wild', 'northern', 'frontier', '.', 'Except', 'it', 'turns', 'out', 'the', 'law', 'is', 'crooked', '.', 'The', 'Judge', 'and', 'the', 'federal', 'marshall', 'are', 'really', 'under', 'the', 'thumb', 'of', 'strongman', 'politician', 'Alexander', 'McNamara', '.', 'After', 'reaching', 'Nome', ',', 'McNamara', 'succeeds', 'in', 'being', 'appointed', 'receiver', 'of', 'all', 'the', 'most', 'lucrative', 'mining', 'claims', 'in', 'the', 'region', ',', 'based', 'on', 'fraudulent', 'disputes', 'over', 'the', 'validity', 'of', 'the', 'miners', \"'\", 'claims', '.', 'Glenister', ',', 'Dextry', ',', 'and', 'a', 'number', 'of', 'naive', 'Swedes', 'are', 'dispossessed', 'of', 'their', 'lands', '.', 'The', 'miners', 'hire', 'lawyers', 'to', 'fight', 'on', 'the', 'legal', 'side', ',', 'and', 'also', 'form', 'a', 'vigilante', 'group', 'to', 'fight', 'the', '\"', 'law', '\"', '.', 'McNamara', 'rules', 'ruthlessly', ',', 'running', 'the', 'mines', 'himself', '.', 'Glenister', 'sinks', 'into', 'despair', ',', 'believing', 'that', 'Helen', 'is', 'in', 'on', 'the', 'conspiracy', 'against', 'the', 'miners', ',', 'and', 'almost', 'loses', 'his', 'stake', 'in', 'the', 'Midas', 'in', 'a', 'night', 'of', 'reckless', 'gambling', '.', 'He', 'is', 'only', 'saved', 'from', 'that', 'fate', 'by', 'Cherry', 'Malotte', ',', 'whose', 'unrequited', 'love', 'for', 'Glenister', 'has', 'brought', 'her', 'to', 'Nome', '.', 'Helen', 'slowly', 'learns', 'about', 'the', 'scheme', 'being', 'perpetrated', 'by', 'McNamara', ',', 'her', 'uncle', ',', 'and', 'others', ',', 'while', 'her', 'affections', 'are', 'torn', 'between', 'Glenister', 'and', 'McNamara', '.']\n",
      "Question:\n",
      "['How', 'do', 'the', 'miners', 'react', 'when', 'McNamara', 'lays', 'claim', 'to', 'their', 'land', '?']\n",
      "Gold answer:\n",
      "['by', 'McNamara', ',', 'her', 'uncle', ',', 'and', 'others', ',', 'while']\n",
      "Selected answer:\n",
      "[291, 300]\n",
      "feat_id_to_feat_name:\n",
      "{1: 'SRL__B-V', 2: 'SRL__B-ARG0', 3: 'SRL__B-ARG1', 4: 'SRL__B-ARG2', 5: 'SRL__B-ARG3', 6: 'SRL__B-ARG4', 7: 'SRL__B-ARG5', 8: 'SRL__B-ARGA', 9: 'SRL__B-ARGM-ADJ', 10: 'SRL__B-ARGM-ADV', 11: 'SRL__B-ARGM-CAU', 12: 'SRL__B-ARGM-COM', 13: 'SRL__B-ARGM-DIR', 14: 'SRL__B-ARGM-DIS', 15: 'SRL__B-ARGM-DSP', 16: 'SRL__B-ARGM-EXT', 17: 'SRL__B-ARGM-GOL', 18: 'SRL__B-ARGM-LOC', 19: 'SRL__B-ARGM-LVB', 20: 'SRL__B-ARGM-MNR', 21: 'SRL__B-ARGM-MOD', 22: 'SRL__B-ARGM-NEG', 23: 'SRL__B-ARGM-PNC', 24: 'SRL__B-ARGM-PRD', 25: 'SRL__B-ARGM-PRP', 26: 'SRL__B-ARGM-PRR', 27: 'SRL__B-ARGM-PRX', 28: 'SRL__B-ARGM-REC', 29: 'SRL__B-ARGM-TMP', 30: 'SRL__B-C-ARG0', 31: 'SRL__B-C-ARG1', 32: 'SRL__B-C-ARG2', 33: 'SRL__B-C-ARG3', 34: 'SRL__B-C-ARG4', 35: 'SRL__B-C-ARGM-ADJ', 36: 'SRL__B-C-ARGM-ADV', 37: 'SRL__B-C-ARGM-CAU', 38: 'SRL__B-C-ARGM-COM', 39: 'SRL__B-C-ARGM-DIR', 40: 'SRL__B-C-ARGM-DIS', 41: 'SRL__B-C-ARGM-DSP', 42: 'SRL__B-C-ARGM-EXT', 43: 'SRL__B-C-ARGM-LOC', 44: 'SRL__B-C-ARGM-MNR', 45: 'SRL__B-C-ARGM-MOD', 46: 'SRL__B-C-ARGM-NEG', 47: 'SRL__B-C-ARGM-PRP', 48: 'SRL__B-C-ARGM-TMP', 49: 'SRL__B-R-ARG0', 50: 'SRL__B-R-ARG1', 51: 'SRL__B-R-ARG2', 52: 'SRL__B-R-ARG3', 53: 'SRL__B-R-ARG4', 54: 'SRL__B-R-ARG5', 55: 'SRL__B-R-ARGM-ADV', 56: 'SRL__B-R-ARGM-CAU', 57: 'SRL__B-R-ARGM-COM', 58: 'SRL__B-R-ARGM-DIR', 59: 'SRL__B-R-ARGM-EXT', 60: 'SRL__B-R-ARGM-GOL', 61: 'SRL__B-R-ARGM-LOC', 62: 'SRL__B-R-ARGM-MNR', 63: 'SRL__B-R-ARGM-MOD', 64: 'SRL__B-R-ARGM-PNC', 65: 'SRL__B-R-ARGM-PRD', 66: 'SRL__B-R-ARGM-PRP', 67: 'SRL__B-R-ARGM-TMP', 68: 'SRL__I-V', 69: 'SRL__I-ARG0', 70: 'SRL__I-ARG1', 71: 'SRL__I-ARG2', 72: 'SRL__I-ARG3', 73: 'SRL__I-ARG4', 74: 'SRL__I-ARG5', 75: 'SRL__I-ARGA', 76: 'SRL__I-ARGM-ADJ', 77: 'SRL__I-ARGM-ADV', 78: 'SRL__I-ARGM-CAU', 79: 'SRL__I-ARGM-COM', 80: 'SRL__I-ARGM-DIR', 81: 'SRL__I-ARGM-DIS', 82: 'SRL__I-ARGM-DSP', 83: 'SRL__I-ARGM-EXT', 84: 'SRL__I-ARGM-GOL', 85: 'SRL__I-ARGM-LOC', 86: 'SRL__I-ARGM-LVB', 87: 'SRL__I-ARGM-MNR', 88: 'SRL__I-ARGM-MOD', 89: 'SRL__I-ARGM-NEG', 90: 'SRL__I-ARGM-PNC', 91: 'SRL__I-ARGM-PRD', 92: 'SRL__I-ARGM-PRP', 93: 'SRL__I-ARGM-PRR', 94: 'SRL__I-ARGM-PRX', 95: 'SRL__I-ARGM-REC', 96: 'SRL__I-ARGM-TMP', 97: 'SRL__I-C-ARG0', 98: 'SRL__I-C-ARG1', 99: 'SRL__I-C-ARG2', 100: 'SRL__I-C-ARG3', 101: 'SRL__I-C-ARG4', 102: 'SRL__I-C-ARGM-ADJ', 103: 'SRL__I-C-ARGM-ADV', 104: 'SRL__I-C-ARGM-CAU', 105: 'SRL__I-C-ARGM-COM', 106: 'SRL__I-C-ARGM-DIR', 107: 'SRL__I-C-ARGM-DIS', 108: 'SRL__I-C-ARGM-DSP', 109: 'SRL__I-C-ARGM-EXT', 110: 'SRL__I-C-ARGM-LOC', 111: 'SRL__I-C-ARGM-MNR', 112: 'SRL__I-C-ARGM-MOD', 113: 'SRL__I-C-ARGM-NEG', 114: 'SRL__I-C-ARGM-PRP', 115: 'SRL__I-C-ARGM-TMP', 116: 'SRL__I-R-ARG0', 117: 'SRL__I-R-ARG1', 118: 'SRL__I-R-ARG2', 119: 'SRL__I-R-ARG3', 120: 'SRL__I-R-ARG4', 121: 'SRL__I-R-ARG5', 122: 'SRL__I-R-ARGM-ADV', 123: 'SRL__I-R-ARGM-CAU', 124: 'SRL__I-R-ARGM-COM', 125: 'SRL__I-R-ARGM-DIR', 126: 'SRL__I-R-ARGM-EXT', 127: 'SRL__I-R-ARGM-GOL', 128: 'SRL__I-R-ARGM-LOC', 129: 'SRL__I-R-ARGM-MNR', 130: 'SRL__I-R-ARGM-MOD', 131: 'SRL__I-R-ARGM-PNC', 132: 'SRL__I-R-ARGM-PRD', 133: 'SRL__I-R-ARGM-PRP', 134: 'SRL__I-R-ARGM-TMP'}\n",
      "[145, 229]\n",
      "['.', 'After', 'reaching', 'Nome', ',', 'McNamara', 'succeeds', 'in', 'being', 'appointed', 'receiver', 'of', 'all', 'the', 'most', 'lucrative', 'mining', 'claims', 'in', 'the', 'region', ',', 'based', 'on', 'fraudulent', 'disputes', 'over', 'the', 'validity', 'of', 'the', 'miners', \"'\", 'claims', '.', 'Glenister', ',', 'Dextry', ',', 'and', 'a', 'number', 'of', 'naive', 'Swedes', 'are', 'dispossessed', 'of', 'their', 'lands', '.', 'The', 'miners', 'hire', 'lawyers', 'to', 'fight', 'on', 'the', 'legal', 'side', ',', 'and', 'also', 'form', 'a', 'vigilante', 'group', 'to', 'fight', 'the', '\"', 'law', '\"', '.', 'McNamara', 'rules', 'ruthlessly', ',', 'running', 'the', 'mines', 'himself', '.']\n",
      "-modeling_layer_iter_000\n",
      "--encoder_block_001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_attention0:max=0.9160908460617065, min=0.0, mean=0.01176310381741844, std=0.04038773946334654\n",
      "head_attention1:max=0.9072096347808838, min=0.0, mean=0.011767141297962684, std=0.05327492892801576\n",
      "head_attention2:max=0.9542418122291565, min=0.0, mean=0.011763365009707994, std=0.04804298452283254\n",
      "head_attention3:max=0.26755422353744507, min=1.89765833056299e-05, mean=0.003121904469626965, std=0.005214380307047593\n",
      "head_attention4:max=0.15406565368175507, min=8.800298267885864e-09, mean=0.003769263949472674, std=0.007052620201022937\n",
      "head_attention5:max=0.9923557043075562, min=1.037977238604797e-34, mean=0.004923546623688887, std=0.04516432229946667\n",
      "head_attention6:max=0.11912782490253448, min=2.681115802261047e-06, mean=0.0034753076165427777, std=0.005740658281295934\n",
      "head_attention7:max=0.2373305708169937, min=4.3457706415436546e-31, mean=0.002280713427758916, std=0.014233026924359762\n",
      "--encoder_block_003\n",
      "head_attention0:max=0.9848043918609619, min=0.0, mean=0.011768413392424942, std=0.05896143829092724\n",
      "head_attention1:max=0.9894368648529053, min=0.0, mean=0.011763445442304649, std=0.08308920562467607\n",
      "head_attention2:max=0.8732866048812866, min=0.0, mean=0.011764264021695062, std=0.048617547943666545\n",
      "head_attention3:max=0.6283539533615112, min=8.275814285436684e-15, mean=0.004391237385378535, std=0.01788220184000336\n",
      "head_attention4:max=0.26943713426589966, min=1.4495676881054465e-09, mean=0.005120093556282864, std=0.012280218221398208\n",
      "head_attention5:max=0.14793525636196136, min=1.190089662372884e-07, mean=0.0044810259149680245, std=0.006894115981450442\n",
      "head_attention6:max=0.3603375256061554, min=2.559004119717656e-09, mean=0.005622807689641608, std=0.01542323466481954\n",
      "head_attention7:max=0.45477280020713806, min=1.1664668164712566e-07, mean=0.004850151183910611, std=0.01492560976144568\n",
      "--encoder_block_005\n",
      "head_attention0:max=0.9013040661811829, min=0.0, mean=0.011864379809400163, std=0.047243150356276443\n",
      "head_attention1:max=0.9803818464279175, min=0.0, mean=0.011769299157707845, std=0.05845862233476604\n",
      "head_attention2:max=0.8141083121299744, min=0.0, mean=0.011764383701039336, std=0.05930475984183783\n",
      "head_attention3:max=0.41098687052726746, min=1.963588147191331e-06, mean=0.006690878837797414, std=0.01089558735532481\n",
      "head_attention4:max=0.20702604949474335, min=1.1565218471787375e-07, mean=0.005334034386686171, std=0.007743146922973529\n",
      "head_attention5:max=0.26691848039627075, min=1.1181392617354291e-10, mean=0.0078937229116425, std=0.016853252950208245\n",
      "head_attention6:max=0.7470889091491699, min=4.833319522390411e-08, mean=0.009431539686553204, std=0.038085396336030024\n",
      "head_attention7:max=0.17527282238006592, min=4.44611572447684e-07, mean=0.005327647064383683, std=0.009660828209564792\n",
      "-modeling_layer_iter_001\n",
      "--encoder_block_001\n",
      "head_attention0:max=0.9294473528862, min=0.0, mean=0.011763212629395222, std=0.03467811891349701\n",
      "head_attention1:max=0.8396841287612915, min=0.0, mean=0.011768759043577404, std=0.03835126674098468\n",
      "head_attention2:max=0.5170908570289612, min=0.0, mean=0.011763348494400454, std=0.028102289149316312\n",
      "head_attention3:max=0.035141706466674805, min=0.00012157837045378983, mean=0.003896584418486747, std=0.002883077197004452\n",
      "head_attention4:max=0.0811590924859047, min=3.584659134503454e-05, mean=0.005585043267393775, std=0.0064804829980730115\n",
      "head_attention5:max=0.6986176371574402, min=1.0172546832665219e-11, mean=0.009285994095432975, std=0.025668894529546692\n",
      "head_attention6:max=0.0530303455889225, min=5.507422247319482e-05, mean=0.0035934155492197404, std=0.002693552718763888\n",
      "head_attention7:max=0.0709729716181755, min=8.088782976756193e-10, mean=0.003652236282374554, std=0.006803442182178257\n",
      "--encoder_block_003\n",
      "head_attention0:max=0.9792405962944031, min=0.0, mean=0.01178663349960406, std=0.05165884218463353\n",
      "head_attention1:max=0.8984388113021851, min=0.0, mean=0.011763040884872854, std=0.05032703888087449\n",
      "head_attention2:max=0.8721521496772766, min=0.0, mean=0.011764758457275464, std=0.04051038861283071\n",
      "head_attention3:max=0.42598575353622437, min=1.536934860268957e-06, mean=0.0069257030024811725, std=0.017655232640934677\n",
      "head_attention4:max=0.35104939341545105, min=2.499770744179841e-05, mean=0.005108610988518328, std=0.013525041975504724\n",
      "head_attention5:max=0.07814256846904755, min=8.774585694482084e-06, mean=0.00575524136260716, std=0.006343269884833929\n",
      "head_attention6:max=0.23934921622276306, min=3.660492779999913e-07, mean=0.005571552070369686, std=0.00929306198556154\n",
      "head_attention7:max=0.17520156502723694, min=2.025103412961471e-06, mean=0.0033117998666290613, std=0.006709037737943221\n",
      "--encoder_block_005\n",
      "head_attention0:max=0.8301130533218384, min=0.0, mean=0.011805004749578941, std=0.04741951180311014\n",
      "head_attention1:max=0.9875857830047607, min=0.0, mean=0.011784618418574243, std=0.06923503912178705\n",
      "head_attention2:max=0.759713888168335, min=0.0, mean=0.011773970106001971, std=0.04639678374429841\n",
      "head_attention3:max=0.1542930006980896, min=4.4427877583075315e-05, mean=0.006428551827728436, std=0.008401172103974095\n",
      "head_attention4:max=0.18017585575580597, min=3.104831876044045e-06, mean=0.006344782860453884, std=0.00801658089512417\n",
      "head_attention5:max=0.24064987897872925, min=4.8798199259181274e-08, mean=0.007242721807512162, std=0.013102501557175083\n",
      "head_attention6:max=0.23166529834270477, min=1.0073113116959576e-06, mean=0.003446821908310586, std=0.00956012490412027\n",
      "head_attention7:max=0.04159729182720184, min=1.3393290601015906e-06, mean=0.0017981448345107645, std=0.002661673189662446\n",
      "-modeling_layer_iter_002\n",
      "--encoder_block_001\n",
      "head_attention0:max=0.9335330128669739, min=0.0, mean=0.011763668535061856, std=0.03638743864210291\n",
      "head_attention1:max=0.7877874374389648, min=0.0, mean=0.01176701260586524, std=0.034629620759189635\n",
      "head_attention2:max=0.7125515937805176, min=0.0, mean=0.011763540344837975, std=0.02910824996100238\n",
      "head_attention3:max=0.02337774820625782, min=0.0003852882655337453, mean=0.0035071363136445315, std=0.0019649569338890207\n",
      "head_attention4:max=0.03909420967102051, min=0.0003400918503757566, mean=0.003704081906425205, std=0.0024324667040424063\n",
      "head_attention5:max=0.12921704351902008, min=2.0448709392439923e-09, mean=0.005647816747714871, std=0.00818155497216539\n",
      "head_attention6:max=0.026101188734173775, min=0.00013015542936045676, mean=0.004160692374657763, std=0.0026674808672567775\n",
      "head_attention7:max=0.033541567623615265, min=1.3826052303045344e-08, mean=0.0012859667963420363, std=0.002170836062081623\n",
      "--encoder_block_003\n",
      "head_attention0:max=0.9888801574707031, min=0.0, mean=0.011783819248587185, std=0.04390991252098017\n",
      "head_attention1:max=0.8725120425224304, min=0.0, mean=0.011763039692181048, std=0.05006479175729712\n",
      "head_attention2:max=0.5831901431083679, min=0.0, mean=0.011764454147407292, std=0.03307160344666588\n",
      "head_attention3:max=0.16944704949855804, min=1.3657856356985576e-07, mean=0.0015715528018755472, std=0.006680052736540545\n",
      "head_attention4:max=0.20783014595508575, min=4.063981123181293e-06, mean=0.0028271286575263133, std=0.007043841819372808\n",
      "head_attention5:max=0.0972088873386383, min=2.0581413991749287e-05, mean=0.005277471962199446, std=0.005538017188893526\n",
      "head_attention6:max=0.04505516216158867, min=2.6635277663444867e-06, mean=0.0016273578547984992, std=0.0019083122429375756\n",
      "head_attention7:max=0.07389181852340698, min=8.028002866922179e-07, mean=0.0015154450420383143, std=0.004242525040475454\n",
      "--encoder_block_005\n",
      "head_attention0:max=0.882529616355896, min=0.0, mean=0.011771880751949742, std=0.057712864005095274\n",
      "head_attention1:max=0.9879042506217957, min=0.0, mean=0.011789671330052013, std=0.06719035669392033\n",
      "head_attention2:max=0.8737497329711914, min=0.0, mean=0.011775770033173224, std=0.03540393759434249\n",
      "head_attention3:max=0.10655952244997025, min=3.53429677488748e-05, mean=0.005210686660509453, std=0.006206011598390251\n",
      "head_attention4:max=0.12992623448371887, min=1.234534920513397e-05, mean=0.005697313944818181, std=0.007290125046249866\n",
      "head_attention5:max=0.15953022241592407, min=2.6227123584021683e-08, mean=0.0056271431411607205, std=0.010695773220584534\n",
      "head_attention6:max=0.04016551375389099, min=6.728592438776104e-07, mean=0.0014913328775196784, std=0.002169092879666201\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_from_args(args_ns, func_eval=evaluate_matplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Results:\")\n",
    "print(json.dumps(metrics, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:docqa] *",
   "language": "python",
   "name": "conda-env-docqa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
