{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "workdir = \"/Users/mihaylov/research/qa-knowreader-long-docs\"\n",
    "sys.path.append(\"/Users/mihaylov/research/qa-knowreader-long-docs\")\n",
    "sys.path.append(\"/Users/mihaylov/research/qa-knowreader-long-docs/docqa\")\n",
    "\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from docqa.commands.evaluate_qanet_semantic_flat import *\n",
    "from docqa.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#debug\n",
    "model_path = \"_trained_models/qanet_semantic_flat_concat_sdp_debug/model.tar.gz\"\n",
    "\n",
    "# model_path = \"_trained_models/bidaf_qa_sumary_span_custom_multiview_eval/model.tar.gz\"\n",
    "# item_ids = \"00936497f5884881f1df23f4834f6739552cee8b##016[15:30];00936497f5884881f1df23f4834f6739552cee8b##005[17:45];0029bdbe75423337b551e42bb31f9a102785376f##023\"\n",
    "# evaluation_data_file = \"/Users/mihaylov/research/document-parsing-pipeline/tests/fixtures/data/narrativeqa/third_party/wikipedia/summaries-all.csv.parsed.jsonl.srl.jsonl.with_q_spans.jsonl.with_exp.with_sdp.json.train.2\"\n",
    "# output_file = \"predictions_dev_jup.json\"\n",
    "\n",
    "model_path=\"_trained_models/oracle_semantic_flat_full/model.tar.gz\"\n",
    "item_ids = \"f4c9b2e062c118b0c15409e78b8e2a3c2ceadcd3##013[179:216];0d0bc01441afbec48663e3b38827e1529a287765##018[145:229]\"\n",
    "item_ids = \"0d0bc01441afbec48663e3b38827e1529a287765##018[145:229]\"\n",
    "evaluation_data_file = \"/Users/mihaylov/research/document-parsing-pipeline/tests/fixtures/data/narrativeqa/third_party/wikipedia/summaries-all.csv.parsed.jsonl.srl.jsonl.with_q_spans.jsonl.with_exp.with_sdp.json.test\"\n",
    "output_file = \"predictions_test_vis.json\"\n",
    "\n",
    "args_ns = create_argparse_namespace(archive_file = workdir + \"/\"+model_path,\n",
    "                              evaluation_data_file = evaluation_data_file,\n",
    "                              output_file = output_file,\n",
    "                              item_ids = item_ids,\n",
    "                              cuda_device = -1,\n",
    "                              batch_size = 1,\n",
    "                              output_attention = \"True\",\n",
    "                              file_open_mode = \"w\",\n",
    "                              overrides = \"\",\n",
    "                              display_attention_matplot = \"True\",\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(data, x, y, ax, x2=None, y1=None):\n",
    "    seaborn.heatmap(data, \n",
    "                    xticklabels=x,\n",
    "                    yticklabels=y, \n",
    "                    vmin=0.0, vmax=1.0, \n",
    "                    square=True, \n",
    "                    cbar=False, ax=ax)\n",
    "\n",
    "    \n",
    "def format_token(tkn_id, tkn, best_span, gold_span):\n",
    "    prefix = \"\"\n",
    "    suffix = \"\"\n",
    "    if tkn_id == best_span[0]:\n",
    "        prefix += \"[\" \n",
    "    if tkn_id == gold_span[0]:\n",
    "        prefix += \"{\" \n",
    "    if tkn_id == gold_span[1]:\n",
    "        suffix += \"}\" \n",
    "    if tkn_id == best_span[1]:\n",
    "        suffix += \"]\" \n",
    "        \n",
    "    return prefix + tkn + suffix\n",
    "        \n",
    "    \n",
    "def display_attentions(tokens, meta, output, output_metadata, feat_id_to_feat_name, crop_range):\n",
    "    modeling_layer_output = output_metadata[\"modeling_layer\"]\n",
    "    modeling_layer_iters = sorted(list(modeling_layer_output.keys()))\n",
    "    \n",
    "    #selected_span = output[\"best_span\"].data[0].tolist()\n",
    "    #gold_span = meta[\"token_spans\"][0]\n",
    "    #tokens = [format_token(tkn_id, tkn, selected_span, gold_span) for tkn_id, tkn in enumerate(metadata[\"passage_tokens\"])]\n",
    "    if crop_range is not None:\n",
    "        print(crop_range)\n",
    "        tokens = tokens[crop_range[0]: crop_range[1]]\n",
    "        \n",
    "    print(tokens)\n",
    "    \n",
    "    axs_head_iter = None\n",
    "    for iter_key_id, iter_key in enumerate(modeling_layer_iters):\n",
    "        iter_value = modeling_layer_output[iter_key]\n",
    "        print(\"-\" + iter_key)\n",
    "        \n",
    "        if iter_value is None:\n",
    "            continue\n",
    "            \n",
    "        encoder_blocks = sorted(list(iter_value.keys()))\n",
    "        encoder_blocks_cnt = len(encoder_blocks)\n",
    "        for encoder_block_id, encoder_block_key in enumerate(encoder_blocks):\n",
    "            print(\"--\" + encoder_block_key)\n",
    "            \n",
    "            encoder_block_value = iter_value[encoder_block_key]\n",
    "                                  \n",
    "            attention_value = encoder_block_value[\"attention\"]\n",
    "            if isinstance(attention_value, list):\n",
    "                attention_value = np.array(attention_value)\n",
    "            \n",
    "            semantic_views_q_value = encoder_block_value.get(\"semantic_views_q\", None)\n",
    "            if semantic_views_q_value is not None and not isinstance(semantic_views_q_value, list):\n",
    "                semantic_views_q_value = semantic_views_q_value.tolist()\n",
    "            \n",
    "            semantic_views_sent_mask_value = encoder_block_value.get(\"semantic_views_sent_mask\", None)\n",
    "            if semantic_views_sent_mask_value is not None and not isinstance(semantic_views_sent_mask_value, list):\n",
    "                semantic_views_sent_mask_value = semantic_views_sent_mask_value.tolist()\n",
    "        \n",
    "            num_heads = attention_value.shape[0]\n",
    "            if axs_head_iter is None:\n",
    "                fig, axs_head_iter = plt.subplots(num_heads, len(modeling_layer_iters) * encoder_blocks_cnt, \n",
    "                                                  figsize=(90 * encoder_blocks_cnt, 240))\n",
    "                \n",
    "            for head_id in range(num_heads):\n",
    "                head_attention = attention_value[head_id]\n",
    "                semantic_views_q_curr = None\n",
    "                if semantic_views_q_value is not None:\n",
    "                    semantic_views_q_curr = semantic_views_q_value[head_id]\n",
    "                    \n",
    "                if semantic_views_sent_mask_value is not None:\n",
    "                    semantic_views_sent_mask_curr = semantic_views_sent_mask_value[head_id]\n",
    "                \n",
    "                #print(\"mask:\")\n",
    "                #print(semantic_views_sent_mask_curr)\n",
    "                # normalize in [0,1.0]\n",
    "                \n",
    "                if crop_range is not None:\n",
    "                    head_attention = head_attention[crop_range[0]:crop_range[1], crop_range[0]:crop_range[1]]\n",
    "                \n",
    "                    if semantic_views_q_curr is not None :\n",
    "                        semantic_views_q_curr[crop_range[0]:crop_range[1]]\n",
    "                \n",
    "                print(\"head_attention{4}:max={0}, min={1}, mean={2}, std={3}\".format(head_attention.max(), head_attention.min(), head_attention.mean(), head_attention.std(), head_id))\n",
    "                head_attention = head_attention/max(0.001, head_attention.max())\n",
    "                \n",
    "                feats = []\n",
    "                if semantic_views_q_curr is not None:\n",
    "                    feats = [feat_id_to_feat_name.get(int(x), \"\") for x in semantic_views_q_curr]\n",
    "                \n",
    "                axs = axs_head_iter[head_id][iter_key_id * encoder_blocks_cnt + encoder_block_id]\n",
    "                axs.set_title(\"iter {0}, block {1}, head {0}\".format(iter_key_id, encoder_block_id, head_id))\n",
    "                #fig, axs = plt.subplots(1, figsize=(10, 10))\n",
    "                draw(head_attention, tokens, tokens if iter_key_id == 0 else feats, ax=axs)\n",
    "                \n",
    "#                 break\n",
    "#             break\n",
    "#         break      \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persist data - remove the break at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def replace_json_lists_with_shapes(json_item):\n",
    "    new_json = {}\n",
    "    for key, value in json_item.items():\n",
    "        if isinstance(value, list):\n",
    "            new_json[key] = str(np.array(value).shape)\n",
    "        elif isinstance(value, dict):\n",
    "            new_json[key] = replace_json_lists_with_shapes(value)\n",
    "        elif isinstance(value, list):\n",
    "            new_json[key] = str(value.shape)\n",
    "        \n",
    "    return new_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for working with output of the model\n",
    "def _persist_data_matplot(file_handle, \n",
    "                  metadata, \n",
    "                  model_output, \n",
    "                  id2label=None,\n",
    "                  id_to_meta=None,\n",
    "                  feat_id_to_feat_name=None,\n",
    "                  display_attention_matplot=True) -> None:\n",
    "    if metadata:\n",
    "        batch_size = len(metadata)\n",
    "        for index, meta in enumerate(metadata):\n",
    "            res = {}\n",
    "            item_id = meta.get(\"id\", \"n/a\")\n",
    "            res[\"id\"] = item_id\n",
    "            res[\"meta\"] = meta\n",
    "            # We persist model output which matches batch_size in length and is not a Variable\n",
    "            for key, value in model_output.items():\n",
    "                if key == \"output_metadata\":\n",
    "                    crop_range = None\n",
    "                    if id_to_meta is not None:\n",
    "                        id_meta_curr = id_to_meta.get(item_id, None)\n",
    "                        if id_meta_curr is not None:\n",
    "                            crop_range = id_meta_curr[\"attention_range\"]\n",
    "        \n",
    "                    sequence_len = model_output[\"span_start_logits\"].shape[-1]\n",
    "                    attentions_metadata = attentions_to_json(value, index, batch_size, sequence_len , crop_range)\n",
    "                    attentions_shapes = replace_json_lists_with_shapes(attentions_metadata)\n",
    "                    print(json.dumps(attentions_shapes, indent=4))\n",
    "                    \n",
    "                    print(\"Passage:\")\n",
    "                    print(meta[\"passage_tokens\"])\n",
    "                    print(\"Question:\")\n",
    "                    print(meta[\"question_tokens\"])\n",
    "                    print(\"Gold answer:\")\n",
    "                    gold_span = meta[\"token_spans\"][0]\n",
    "                    print(meta[\"passage_tokens\"][gold_span[0]:gold_span[1]+1])\n",
    "                    \n",
    "                    print(\"Selected answer:\")\n",
    "                    print(meta[\"token_spans\"][0])\n",
    "                    \n",
    "                    print(\"feat_id_to_feat_name:\")\n",
    "                    print(feat_id_to_feat_name)\n",
    "                    \n",
    "                    \n",
    "                    display_attentions(meta[\"passage_tokens\"], meta, model_output, attentions_metadata, feat_id_to_feat_name, crop_range)\n",
    "                    # res[\"attentions_metadata\"] = attentions_metadata\n",
    "                    #print(attentions_metadata)\n",
    "\n",
    "                curr_value = value\n",
    "                if isinstance(value, torch.autograd.Variable) or isinstance(value, Tensor):\n",
    "                    curr_value = value.data.tolist()\n",
    "\n",
    "                if not isinstance(curr_value, torch.autograd.Variable) \\\n",
    "                        and isinstance(curr_value, list) \\\n",
    "                        and len(curr_value) == batch_size:\n",
    "                    val = curr_value[index]\n",
    "                    res[key] = val\n",
    "\n",
    "            if \"label_probs\" in res and id2label is not None:\n",
    "                labels_by_probs = sorted([[id2label[li], lp] for li, lp in enumerate(res[\"label_probs\"])], key=lambda x:x[1], reverse=True)\n",
    "                res[\"labels_by_prob\"] = labels_by_probs\n",
    "                res[\"label_predicted\"] = labels_by_probs[0][0]\n",
    "\n",
    "            file_handle.write(json.dumps(res))\n",
    "            file_handle.write(\"\\n\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate evaluate_matplot\n",
    "def evaluate_matplot(model: Model,\n",
    "             instances: Iterable[Instance],\n",
    "             data_iterator: DataIterator,\n",
    "             output_file: str = None,\n",
    "             file_mode=\"w\",\n",
    "             id_to_meta: Dict[str, Any] = {},\n",
    "             feat_id_to_feat_name: Dict[int, str]= {},\n",
    "             display_attention_matplot = False,\n",
    "             ) -> Dict[str, Any]:\n",
    "    model.eval()\n",
    "\n",
    "    iterator = data_iterator(instances, num_epochs=1, shuffle=False)\n",
    "    logger.info(\"Iterating over dataset\")\n",
    "    generator_tqdm = Tqdm.tqdm(iterator, total=data_iterator.get_num_batches(instances))\n",
    "    with ExitStack() as stack:\n",
    "        if output_file is None:\n",
    "            file_handle = None\n",
    "        else:\n",
    "            file_handle = stack.enter_context(open(output_file, file_mode))\n",
    "\n",
    "        for batch in generator_tqdm:\n",
    "            model_output = model(**batch)\n",
    "            metrics = model.get_metrics()\n",
    "            if file_handle:\n",
    "                id2label = model.vocab.get_index_to_token_vocabulary(\"labels\")\n",
    "                _persist_data_matplot(file_handle, batch.get(\"metadata\"), model_output,\n",
    "                              id2label=id2label,\n",
    "                              id_to_meta=id_to_meta,\n",
    "                              feat_id_to_feat_name=feat_id_to_feat_name,\n",
    "                              display_attention_matplot=display_attention_matplot)\n",
    "            description = ', '.join([\"%s: %.2f\" % (name, value) for name, value in metrics.items()]) + \" ||\"\n",
    "            generator_tqdm.set_description(description)\n",
    "\n",
    "    return model.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics = evaluate_from_args(args_ns, func_eval=evaluate_matplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Results:\")\n",
    "print(json.dumps(metrics, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:docqa] *",
   "language": "python",
   "name": "conda-env-docqa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
